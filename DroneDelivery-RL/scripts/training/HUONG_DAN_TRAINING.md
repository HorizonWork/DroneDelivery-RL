# HÆ¯á»šNG DáºªN HUáº¤N LUYá»†N PPO
## Energy-Aware Indoor Drone Navigation System

---

## ğŸ¯ Tá»”NG QUAN

Há»‡ thá»‘ng huáº¥n luyá»‡n PPO nÃ y thá»±c hiá»‡n viá»‡c training agent Ä‘á»ƒ Ä‘áº¡t Ä‘Æ°á»£c **96% success rate** vÃ  **25% energy savings** nhÆ° trong bÃ¡o cÃ¡o nghiÃªn cá»©u. Sá»­ dá»¥ng **curriculum learning** vá»›i 3 phases vÃ  tá»•ng cá»™ng **5 million timesteps**.

### Má»¥c tiÃªu huáº¥n luyá»‡n:
- ğŸ¯ **Success Rate**: â‰¥96% navigation success
- âš¡ **Energy Savings**: â‰¥25% so vá»›i A* Only baseline  
- ğŸ›¡ï¸ **Safety**: â‰¤2% collision rate
- ğŸ¯ **Precision**: â‰¤5cm ATE localization error
- â±ï¸ **Efficiency**: <120s flight time

---

## ğŸ“ Cáº¤U TRÃšC TRAINING SCRIPTS

scripts/training/
â”œâ”€â”€ train_ppo.py # ğŸš Main PPO training (5M timesteps)

â”œâ”€â”€ train_phase.py # ğŸ¯ Individual phase training
â”œâ”€â”€ hyperparameter_search.py # ğŸ” Auto hyperparameter optimization
â”œâ”€â”€ monitor_training.py # ğŸ“Š Real-time monitoring
â”œâ”€â”€ resume_training.py # ğŸ”„ Resume tá»« checkpoint

Windows: KhÃ´ng cáº§n (Python packages sáº½ handle)

---

## ğŸš€ QUY TRÃŒNH HUáº¤N LUYá»†N Äáº¦Y Äá»¦

### BÆ°á»›c 1: Chuáº©n bá»‹ mÃ´i trÆ°á»ng
Activate conda environment
```bash
conda activate drone_delivery_rl
```

Kiá»ƒm tra installation
```bash
python scripts/setup/verify_installation.py
```

Táº¡o thÆ° má»¥c káº¿t quáº£
```bash
mkdir -p models/checkpoints results/training logs
```

Windows: KhÃ´ng cáº§n (Python packages sáº½ handle)

### BÆ°á»›c 2: (TÃ¹y chá»n) TÃ¬m hyperparameters tá»‘i Æ°u
Cháº¡y hyperparameter search (50 trials, ~24 giá»)
```bash
python scripts/training/hyperparameter_search.py \
--config config/main_config.yaml \
--trials 50 \
--timeout 24 \
--output results/hyperparameter_search
```

Káº¿t quáº£: TÃ¬m Ä‘Æ°á»£c best parameters cho PPO
Windows: KhÃ´ng cáº§n (Python packages sáº½ handle)

**Thá»i gian**: 12-24 giá» (cÃ³ thá»ƒ skip náº¿u dÃ¹ng default parameters)

### BÆ°á»›c 3: Huáº¥n luyá»‡n chÃ­nh - CÃ³ 3 phÆ°Æ¡ng phÃ¡p

#### PhÆ°Æ¡ng phÃ¡p A: Main PPO Training (KHUYáº¾N NGHá»Š) â­
Huáº¥n luyá»‡n complete vá»›i curriculum learning
```bash
python scripts/training/train_ppo.py \
--config config/main_config.yaml \
--name ppo_energy_aware_5floors
```

Vá»›i best hyperparameters (náº¿u Ä‘Ã£ search)
```bash
python scripts/training/train_ppo.py \
--config results/hyperparameter_search/best_hyperparameters.json \
--name ppo_optimized
```

Windows: KhÃ´ng cáº§n (Python packages sáº½ handle)

#### PhÆ°Æ¡ng phÃ¡p B: Full Curriculum Training
Training tá»«ng phase tuáº§n tá»± (3 phases)
```bash
python scripts/training/train_full_curriculum.py \
--config config/main_config.yaml \
--output-dir models/curriculum_training
```

Windows: KhÃ´ng cáº§n (Python packages will handle)

#### PhÆ°Æ¡ng phÃ¡p C: Individual Phase Training
Train tá»«ng phase riÃªng biá»‡t (debug mode)
```bash
python scripts/training/train_phase.py --phase single_floor
python scripts/training/train_phase.py --phase two_floor
python scripts/training/train_phase.py --phase five_floor
```

Windows: KhÃ´ng cáº§n (Python packages will handle)

**Thá»i gian**: 8-15 giá» cho complete training

### BÆ°á»›c 4: Monitoring (cháº¡y parallel)
Má»Ÿ terminal thá»© 2 Ä‘á»ƒ monitor training
```bash
python scripts/training/monitor_training.py \
--experiment ppo_energy_aware_5floors \
--interval 30
```

Sáº½ hiá»ƒn thá»‹ live dashboard vá»›i:
- Progress bar vÃ  remaining time
- Success rate, energy consumption
- System resources (CPU, RAM, GPU)
- Alerts náº¿u cÃ³ váº¥n Ä‘á»
Windows: KhÃ´ng cáº§n (Python packages will handle)

### BÆ°á»›c 5: Resume náº¿u bá»‹ giÃ¡n Ä‘oáº¡n
Resume tá»« checkpoint má»›i nháº¥t
```bash
python scripts/training/resume_training.py \
--checkpoint models/checkpoints/ppo_step_03000000_timestamp.pt \
--config config/main_config.yaml
```

Windows: KhÃ´ng cáº§n (Python packages will handle)

---

## ğŸ“Š CURRICULUM LEARNING PHASES

### Phase 1: Single Floor Static (1M timesteps)
**Má»¥c tiÃªu**: Há»c basic navigation vÃ  obstacle avoidance
- ğŸ¢ **Environment**: 1 floor, static obstacles only
- ğŸ“Š **Target**: 85% success rate
- âš¡ **Energy**: ~800J per episode
- â±ï¸ **Time**: ~2-3 giá» training

### Phase 2: Two Floor Dynamic (2M timesteps)  
**Má»¥c tiÃªu**: Há»c multi-floor navigation vÃ  dynamic obstacles
- ğŸ¢ **Environment**: 2 floors, 3 dynamic obstacles
- ğŸ“Š **Target**: 90% success rate  
- âš¡ **Energy**: ~700J per episode
- â±ï¸ **Time**: ~4-5 giá» training

### Phase 3: Five Floor Complex (2M timesteps)
**Má»¥c tiÃªu**: Mastery complex 5-floor navigation
- ğŸ¢ **Environment**: 5 floors, 5 dynamic obstacles + humans
- ğŸ“Š **Target**: 96% success rate
- âš¡ **Energy**: ~610J per episode  
- â±ï¸ **Time**: ~4-6 giá» training

### Automatic Phase Transition:
- **Success criteria met**: Auto advance to next phase
- **Early completion**: Phase cÃ³ thá»ƒ complete trÆ°á»›c timestep limit
- **Failure handling**: Retry phase náº¿u khÃ´ng Ä‘áº¡t target

---

## ğŸ“ˆ MONITORING VÃ€ TRACKING

### Live Training Dashboard:
==================================================
ğŸš
ğŸ“Š TRAINING PROGRESS
Timestep: 2,347,891 / 5,000,000
Progress: [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘] 46.9%

ğŸ¯ PERFORMANCE METRICS
Success Rate: 91.2%
Energy Consumption: 687J

ğŸ’» SYSTEM RESOURCES
CPU Usage: 78.4%
Memory Usage: 65.2%
Disk Free: 45.2GB
GPU Memory

ğŸ’¾ LATEST CHECKPOINT
File: ppo_step_02300000_20251106_201530.pt

â±ï¸ Training Time: 8.3 hours

Last Update: 20:26:15
Windows: KhÃ´ng cáº§n (Python packages will handle)

### Alert System:
- âš ï¸ **Low Success Rate**: <20% success rate alert
- âš ï¸ **High Memory Usage**: >90% RAM usage
- âš ï¸ **Training Stalled**: No checkpoint >5 phÃºt  
- âš ï¸ **Loss Explosion**: Policy loss >100

---

## ğŸ”§ Cáº¤U HÃŒNH TRAINING

### Default PPO Configuration:
```yaml
config/main_config.yaml
rl:
  ppo:
    learning_rate: 3e-4 # Optimized for drone control
    rollout_length: 2048 # Long episodes cho exploration
    epochs: 10 # PPO update epochs
    clip_range: 0.2 # PPO clipping parameter
    entropy_coef: 0.01 # Exploration bonus
    value_loss_coef: 0.5 # Value function weight
    gamma: 0.99
```

```yaml
training:
  total_timesteps: 5_000_000 # Research paper target
 eval_frequency: 50_000 # Evaluate má»—i 50k timesteps
```

Windows: KhÃ´ng cáº§n (Python packages will handle)

### Customization Options:
Training vá»›i custom parameters
```bash
python scripts/training/train_ppo.py \
--config config/main_config.yaml \
--name custom_experiment \
--timesteps 3000000 # Override total timesteps
```

Training vá»›i GPU (náº¿u cÃ³)
```bash
export CUDA_VISIBLE_DEVICES=0
python scripts/training/train_ppo.py
```

Training vá»›i reduced memory
```bash
python scripts/training/train_ppo.py \
--config config/low_memory_config.yaml
```

Windows: KhÃ´ng cáº§n (Python packages will handle)

---

## ğŸ“Š TRACKING RESULTS

### Training Outputs:
- **Checkpoints**: `models/checkpoints/ppo_step_XXXXXXXX_timestamp.pt`
- **Final model**: `models/checkpoints/ppo_final.pt`  
- **Training logs**: `logs/training.log`
- **TensorBoard**: `runs/ppo_drone_YYYYMMDD_HHMMSS/`
- **Phase results**: `models/curriculum_training/phase_results.json`

### TensorBoard Visualization:
View training curves
```bash
tensorboard --logdir runs/
```

Browser: http://localhost:6006
Metrics available:
- Episode rewards, success rates
- Energy consumption trends
- Policy/value losses
- Learning curves per phase
Windows: KhÃ´ng cáº§n (Python packages will handle)

### Key Metrics Ä‘á»ƒ theo dÃµi:
1. **Episode Reward**: Should increase from -100 to 500+
2. **Success Rate**: Target 85% â†’ 90% â†’ 96% across phases
3. **Energy Consumption**: Should decrease to ~610J final
4. **Policy Loss**: Should converge to <0.1
5. **Value Loss**: Should stabilize <1.0

---

## â±ï¸ TIMELINE VÃ€ EXPECTATIONS

### Complete Training Timeline:
| Phase | Timesteps | Duration | Success Target | Energy Target |
|-------|-----------|----------|----------------|---------------|
| Phase 1 | 1M | 2-3 giá» | 85% | ~800J |
| Phase 2 | 2M | 4-5 giá» | 90% | ~700J |  
| Phase 3 | 2M | 4-6 giá» | 96% | ~610J |
| **TOTAL** | **5M** | **10-14 giá»** | **96%** | **610J** |

### Checkpoints Schedule:
- **Every 100k timesteps**: Automatic checkpoint save
- **Every 500k timesteps**: Full evaluation + best model save
- **Phase completions**: Phase-specific checkpoints
- **Final completion**: `ppo_final.pt` production-ready model

---

## ğŸ”„ RESUME VÃ€ RECOVERY

### Training bá»‹ giÃ¡n Ä‘oáº¡n:
TÃ¬m checkpoint má»›i nháº¥t
```bash
ls -la models/checkpoints/ | grep ppo_step | tail -1
```

Resume tá»« checkpoint
```bash
python scripts/training/resume_training.py \
--checkpoint models/checkpoints/ppo_step_025000_20251106.pt \
--config config/main_config.yaml
```

Windows: KhÃ´ng cáº§n (Python packages will handle)

### Recovery tá»« failed training:
Check logs Ä‘á»ƒ identify issue
```bash
tail -100 logs/training.log
```

Resume tá»« checkpoint stable trÆ°á»›c Ä‘Ã³
```bash
python scripts/training/resume_training.py \
--checkpoint models/checkpoints/ppo_step_02000000_20251106.pt \
--timesteps 50000 # Continue to full target
```

Windows: KhÃ´ng cáº§n (Python packages will handle)

### Backup strategy:
Regular backup cá»§a important checkpoints
cp models/checkpoints/ppo_step_01000000_.pt backup/
```bash
cp models/checkpoints/ppo_step_0200000_.pt backup/
cp models/checkpoints/ppo_step_03000000_.pt backup/
```

Windows: KhÃ´ng cáº§n (Python packages will handle)

---

## ğŸ› TROUBLESHOOTING

### Issue 1: "CUDA out of memory"
Giáº£m batch size
```yaml
config/main_config.yaml:
rl:
  ppo:
    batch_size: 128 # Tá»« 256
```

Hoáº·c dÃ¹ng CPU
```bash
export CUDA_VISIBLE_DEVICES=""
```

Windows: KhÃ´ng cáº§n (Python packages will handle)

### Issue 2: "Training too slow"
DÃ¹ng GPU náº¿u cÃ³
```bash
export CUDA_VISIBLE_DEVICES=0
```
TÄƒng batch size (náº¿u cÃ³ RAM)
```yaml
batch_size: 512
```
DÃ¹ng multiple processes (advanced)
```yaml
num_workers: 4
```

Windows: KhÃ´ng cáº§n (Python packages will handle)

### Issue 3: "Success rate khÃ´ng improve"
Check hyperparameters
```bash
python scripts/training/hyperparameter_search.py --trials 20
```
Hoáº·c adjust learning rate
```yaml
learning_rate: 1e-4 # Giáº£m tá»« 3e-4
```
TÄƒng exploration
```yaml
entropy_coef: 0.02 # TÄƒng tá»« 0.01
```

Windows: KhÃ´ng cáº§n (Python packages will handle)

### Issue 4: "Loss exploding"
Giáº£m learning rate
learning_rate: 1e-4
Adjust clip range
clip_range: 0.1 # Giáº£m tá»« 0.2
Check gradient clipping
max_grad_norm: 0.5
Windows: KhÃ´ng cáº§n (Python packages will handle)

### Issue 5: "Training stalled"
Restart tá»« earlier checkpoint
```bash
python scripts/training/resume_training.py \
--checkpoint models/checkpoints/ppo_step_015000_*.pt
```

Hoáº·c adjust curriculum thresholds
Windows: KhÃ´ng cáº§n (Python packages will handle)

---

## ğŸ“Š SUCCESS INDICATORS

### Phase 1 Success (1M timesteps):
- âœ… Success rate: 85%+ 
- âœ… Stable navigation trong single floor
- âœ… Basic obstacle avoidance  
- âœ… Energy consumption: ~800J

### Phase 2 Success (3M timesteps):
- âœ… Success rate: 90%+
- âœ… Multi-floor navigation
- âœ… Dynamic obstacle handling
- âœ… Energy optimization: ~700J  

### Phase 3 Success (5M timesteps):
- âœ… Success rate: 96%+
- âœ… Complex 5-floor navigation
- âœ… Human obstacle avoidance
- âœ… Energy efficiency: ~610J
- âœ… **READY FOR TABLE 3 EVALUATION**

### Final Success Criteria:
ğŸ‰ TRAINING HOÃ€N THÃ€NH KHI:
```yaml
âœ… 5,000,000 timesteps completed
âœ… Success rate: 96%+ achieved
âœ… Energy consumption â‰¤700J average
âœ… Collision rate â‰¤2%
âœ… All 3 curriculum phases passed
```

Windows: KhÃ´ng cáº§n (Python packages will handle)

---

## ğŸ’» COMMANDS REFERENCE

### Huáº¥n luyá»‡n cÆ¡ báº£n:
Standard training
```bash
python scripts/training/train_ppo.py
```

Vá»›i custom config
```bash
python scripts/training/train_ppo.py --config config/custom.yaml
```

Vá»›i experiment name
```bash
python scripts/training/train_ppo.py --name experiment_v2
```

Windows: KhÃ´ng cáº§n (Python packages will handle)

### Curriculum training:
Complete curriculum
```bash
python scripts/training/train_full_curriculum.py
```

Individual phases
```bash
python scripts/training/train_phase.py --phase single_floor
python scripts/training/train_phase.py --phase two_floor
```

Windows: KhÃ´ng cáº§n (Python packages will handle)

### Monitoring:
Real-time monitor
```bash
python scripts/training/monitor_training.py
```

Monitor specific experiment
```bash
python scripts/training/monitor_training.py --experiment ppo_v3
```

Windows: KhÃ´ng cáº§n (Python packages will handle)

### Resume vÃ  recovery:
Resume training
```bash
python scripts/training/resume_training.py \
--checkpoint models/checkpoints/ppo_step_XXXXXXXX.pt
```

Resume vá»›i different target
```bash
python scripts/training/resume_training.py \
--checkpoint ppo_step_30000.pt \
--timesteps 6000000 # Extend training
```

Windows: KhÃ´ng cáº§n (Python packages will handle)

### Hyperparameter optimization:
Quick search (10 trials)
```bash
python scripts/training/hyperparameter_search.py --trials 10 --timeout 6
```

Full search (50 trials)
```bash
python scripts/training/hyperparameter_search.py --trials 50 --timeout 24
```

Use found parameters
```bash
python scripts/training/train_ppo.py \
--config results/hyperparameter_search/best_hyperparameters.json
```

Windows: KhÃ´ng cáº§n (Python packages will handle)

---

## ğŸ“‹ TRAINING CHECKLIST

### Pre-Training:
- [ ] **Environment setup** completed
- [ ] **Config files** prepared
- [ ] **Disk space** â‰¥15GB available
- [ ] **Memory** â‰¥8GB available  
- [ ] **Time allocation** 10-15 giá»

### During Training:
- [ ] **Monitor progress** live dashboard
- [ ] **Check alerts** memory, success rate warnings
- [ ] **Backup checkpoints** important milestones
- [ ] **Log issues** any errors or stalls

### Post-Training:
- [ ] **Final model** `ppo_final.pt` created
- [ ] **Success rate** â‰¥96% achieved
- [ ] **Energy target** â‰¤700J achieved  
- [ ] **Training completed** 5M timesteps
- [ ] **Ready for evaluation** Table 3 generation

---

## ğŸ¯ EXPECTED RESULTS

### Training Curves (TensorBoard):
- **Episode Rewards**: -100 â†’ 500+ increasing trend
- **Success Rates**: 0% â†’ 85% â†’ 90% â†’ 96% phase progression
- **Energy Consumption**: 1000J â†’ 800J â†’ 700J â†’ 610J decreasing
- **Policy Loss**: High â†’ Converge to <0.1
- **Value Loss**: Unstable â†’ Stable <1.0

### Final Model Performance:
ğŸ† TRAINING SUCCESS METRICS:
âœ… Success Rate: 96.2% (Target: â‰¥96%)
âœ… Energy Consumption: ~610J average (Target: â‰¤700J)
âœ… Energy Savings: 78% vs A* Only (Target: â‰¥25%)
âœ… Flight Time: 31.5s average
âœ… Collision Rate: 0.7% (Target: â‰¤2%)

ğŸ¯ READY FOR TABLE 3 EVALUATION!

Windows: KhÃ´ng cáº§n (Python packages will handle)

---

## ğŸ” MONITORING METRICS

### Key metrics Ä‘á»ƒ track:
1. **Episode Reward Trend**: Should show clear improvement
2. **Success Rate Progress**: Must reach 96% final
3. **Energy Efficiency**: Must show decreasing trend to 610J
4. **Policy Stability**: Loss convergence indicates learning
5. **System Health**: No memory leaks or resource issues

### Warning signs:
- ğŸš¨ Success rate giáº£m hoáº·c stagnant
- ğŸš¨ Energy consumption tÄƒng
- ğŸš¨ Loss exploding (>100)
- ğŸš¨ Training stalled (no checkpoints >10 phÃºt)
- ğŸš¨ Memory usage >90%

---

## ğŸ† COMPLETION CRITERIA

**Training ÑÑ‡Ğ¸Ñ‚Ğ°ĞµÑ‚ÑÑ thÃ nh cÃ´ng khi:**
1. âœ… **5,000,000 timesteps** hoÃ n thÃ nh
2. âœ… **96%+ success rate** stable trong 100+ episodes
3. âœ… **610J energy consumption** average achieved
4. âœ… **All curriculum phases** passed successfully
5. âœ… **Final model** `ppo_final.pt` saved
6. âœ… **Evaluation ready** cho Table 3 generation

**Estimated Total Time**: 10-15 giá» (depending on hardware)

**ğŸ‰ Success â†’ Ready for comprehensive evaluation vÃ  Table 3 results generation!** ğŸšğŸ“Šâœ¨